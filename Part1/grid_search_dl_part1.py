# -*- coding: utf-8 -*-
"""Grid_Search_DL_Part1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E_VWDMTgnoLGWV72Sqy2Kh1XJ2IBQahE

### Evaluate model with GridSearch
"""
#to get data
#!git clone https://github.com/HajarBenzaouia/DataSet_Bark101.git

from keras.models import Model
from keras.layers import Activation,Concatenate,GlobalAveragePooling2D, BatchNormalization,Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D
from keras.utils import plot_model
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
import os

#Dirs path 
DATADIR_TEST = "DataSet_Bark101/Bark101_test"
DATADIR_TRAIN = "DataSet_Bark101/Bark101_train"
#names of sub folders
CLASSES = range(0, 101)
#convert int to str
CLASSES = [str(i) for i in CLASSES]
#Create empty numpy arrays for training and test 
trainX = []
trainY = []
testX = []
testY = []
#retrive all images in Bark101_test
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import array_to_img
#Get train data
for category in CLASSES:  
  path = os.path.join(DATADIR_TRAIN,category)  # create path to dogs and cats DataSet_Bark101/Bark101_test/0
  for img in os.listdir(path):  # iterate over each image per dogs and cats
    img = load_img(os.path.join(path,img))
    img_array = img_to_array(img)
    #plt.imshow(img_array)  # graph it
    #plt.show()  # display!
    trainX.append(img_array)
    trainY.append(int(category))
#Get test data
for category in CLASSES:  
  path = os.path.join(DATADIR_TEST,category)  # create path to dogs and cats DataSet_Bark101/Bark101_test/0
  for img in os.listdir(path):  # iterate over each image per dogs and cats
    img = load_img(os.path.join(path,img))
    img_array = img_to_array(img)
    #plt.imshow(img_array)  # graph it
    #plt.show()  # display!
    testX.append(img_array)
    testY.append(int(category))
trainX = np.array(trainX)
trainY = np.array(trainY)
testX = np.array(testX)
testY = np.array(testY)

trainY = to_categorical(trainY, num_classes= 101)
trainY.shape

from keras.models import Model
from keras.layers import Activation,Concatenate,GlobalAveragePooling2D, BatchNormalization,Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.utils import plot_model
from keras.optimizers import Adam
from keras.callbacks import LearningRateScheduler, ModelCheckpoint
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
from datetime import datetime
from tqdm import tqdm
from imutils import paths
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
from keras.utils import to_categorical
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

num_classes = 101
#Création de CNN
def build_model():
   inputs = Input(shape=(224,224,3)) 
   conv1 = Conv2D(96, kernel_size=7, padding='same',strides=2, activation='relu')(inputs)
   maxpool1 = MaxPooling2D(pool_size=(3,3),strides=2)(conv1)
   
   #1er Fire Module
   fire1_squeeze = Conv2D(16, kernel_size=1, padding='same',activation='relu')(maxpool1)
   fire1_expand1 = Conv2D(64, kernel_size=1, padding='same',activation='relu')(fire1_squeeze)
   fire1_expand2 = Conv2D(64, kernel_size=3, padding='same',activation='relu')(fire1_squeeze)
   concatenate_1 = concatenate([fire1_expand1, fire1_expand2])
   
   #2eme Fire Module
   fire2_squeeze = Conv2D(16, kernel_size=1, padding='same',activation='relu')(concatenate_1)
   fire2_expand1 = Conv2D(64, kernel_size=1, padding='same',activation='relu')(fire2_squeeze)
   fire2_expand2 = Conv2D(64, kernel_size=3, padding='same',activation='relu')(fire2_squeeze)
   concatenate_2= concatenate([fire2_expand1, fire2_expand2])
   
   # 3eme Fire Module
   fire3_squeeze = Conv2D(32, kernel_size=1, padding='same',activation='relu')(concatenate_2)
   fire3_expand1 = Conv2D(128, kernel_size=1, padding='same',activation='relu')(fire3_squeeze)
   fire3_expand2 = Conv2D(128, kernel_size=3, padding='same',activation='relu')(fire3_squeeze)
   concatenate_3= concatenate([fire3_expand1, fire3_expand2])
   
   # max pooling
   maxpool2 = MaxPooling2D(pool_size=(3,3),strides=2)(concatenate_3)
   
   # 4eme Fire Module
   fire4_squeeze = Conv2D(32, kernel_size=1, padding='same',activation='relu')(maxpool2)
   fire4_expand1 = Conv2D(128, kernel_size=1, padding='same',activation='relu')(fire4_squeeze)
   fire4_expand2 = Conv2D(128, kernel_size=3, padding='same',activation='relu')(fire4_squeeze)
   concatenate_4= concatenate([fire4_expand1, fire4_expand2])
   
   #FC
   dropout_1 = Dropout(0.5)(concatenate_4)
   conv2 = Conv2D(num_classes, kernel_size=1, padding='valid', activation='relu')(dropout_1)
   global_average_pooling2d_1 = GlobalAveragePooling2D()(conv2)
   softmax  = Activation('softmax')(global_average_pooling2d_1)

   #Compilation
   model = Model(inputs=inputs, outputs=softmax)
   adam = Adam(learning_rate=0.001)
   model.compile(loss='categorical_crossentropy', optimizer= adam, metrics=['accuracy'])
   #Visualiser le modèle
   #print(model.summary())
   
   return model


model = KerasClassifier(build_fn=build_model, epochs=10, verbose=1)

# define the grid search parameters
batch_size = [8, 16, 32, 64, 128]
epochs = [20,40,60,80,100]
param_grid = dict(batch_size=batch_size, epochs=epochs)
grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)
grid_result = grid.fit(trainX, trainY)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))